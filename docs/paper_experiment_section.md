# 论文中的实验描述章节（可直接使用）

## 4.1 实验目的

为了评估RDMA NIC（Network Interface Card）上硬件序列化能力的性能特征，我们设计了A1实验。由于直接访问NIC硬件序列化单元需要特定的硬件平台和驱动支持，我们采用**软件模拟方法**来评估和预测硬件序列化的性能。实验通过在标准x86_64平台上精确测量序列化/反序列化操作的核心计算（memcpy）性能，来评估NIC硬件序列化单元的潜在性能。具体实验目标包括：（1）验证各类Token（PD、MR、CQ、QP）的真实字节大小和压缩比，为硬件设计提供数据参考；（2）量化序列化/反序列化操作的延迟和吞吐量，评估NIC硬件序列化单元的性能需求；（3）分析不同数据规模对性能的影响，为硬件批量处理设计提供依据；（4）深入理解encode和decode操作性能差异的根本原因，指导硬件加速器的设计优化。

## 4.2 实验环境

### 硬件平台

实验在配备Intel Core i5-12490F处理器的Linux系统上执行。该处理器采用12代酷睿架构，具有6个物理核心和12个逻辑线程，基础频率为3.0GHz，最高睿频可达4.6GHz。缓存层次结构包括：L1数据缓存288KB（6个实例，每个核心48KB）、L1指令缓存192KB（每个核心32KB）、L2缓存7.5MB（6个实例，每个核心1.25MB）、L3缓存20MB（共享）。系统内存为DDR4，总容量为7.7GB，可用容量为6.6GB。操作系统为基于Linux内核6.6.87.2的WSL2（Windows Subsystem for Linux 2）环境。

### 软件环境

实验程序采用C++17标准编写，使用GCC 12.4.0编译器（conda-forge版本）编译，编译优化选项为`-O2 -Wall -Wextra`。构建系统使用CMake 3.15或更高版本。为确保测量准确性，实验在单线程模式下执行，CPU频率调节器设置为performance模式（如适用），以减少频率变化对测量结果的影响。所有实验在相同系统负载条件下执行，避免其他进程干扰。需要注意的是，在WSL2环境中，CPU频率调节由Windows主机管理，但实验仍能反映真实的性能特征。

### 实验工具

实验程序`exp_a1_compress`采用微基准测试方法，使用高精度计时器（`std::chrono::high_resolution_clock`）进行测量，精度达到纳秒级。程序仅依赖标准C++库，无外部依赖，确保结果的可重复性和可移植性。

### 软件模拟与硬件序列化的对应关系

本实验采用软件模拟方法评估NIC硬件序列化能力，其合理性基于以下考虑：

1. **操作本质对应**：NIC硬件序列化单元的核心操作是将Token结构体转换为字节流（encode）和将字节流转换为Token结构体（decode），这些操作在软件层面对应为memcpy操作。通过精确测量memcpy的性能，可以评估硬件序列化单元的理论性能上限。

2. **性能瓶颈分析**：硬件序列化单元的性能主要受限于内存访问带宽和缓存效率，而非算法复杂度。软件模拟通过测量内存访问模式对性能的影响，可以揭示硬件设计中的关键瓶颈。

3. **设计指导价值**：软件模拟结果可以为NIC硬件设计提供以下指导：（1）序列化单元的吞吐量需求；（2）缓存层次结构的设计要求；（3）批量处理窗口大小的优化方向。

## 4.3 实验设计

### 测试工作负载

实验涵盖四种Token类型：PD Token（8字节）、MR Token（12字节）、CQ Token（12字节）和QP Token（16字节）。测试数据规模（N值）从1,000到1,000,000，覆盖不同应用场景。Token字段值采用两种分布模式：（1）随机分布：使用Mersenne Twister伪随机数生成器生成字段值，模拟真实场景的多样性；（2）典型分布：使用固定模式生成字段值，模拟典型应用场景。

### 性能指标

实验测量以下性能指标：

- **延迟指标**：
  - 平均延迟（avg_latency_ns）：所有操作的平均延迟，单位为纳秒/操作（ns/op）
  - 95th分位数延迟（p95_latency_ns）：95%的操作延迟小于等于该值，单位为纳秒
  - 注：使用纳秒作为单位，更符合NIC硬件序列化单元的延迟特征（通常在纳秒级）

- **带宽指标**：
  - 编码带宽（encode_bandwidth_MBps）：编码操作的数据传输带宽，单位为MB/s
  - 解码带宽（decode_bandwidth_MBps）：解码操作的数据传输带宽，单位为MB/s
  - 计算公式：`bandwidth = (bytes_per_token × 1e9) / (avg_latency_ns × 1024 × 1024)`

- **吞吐量指标**：
  - 编码吞吐量（encode_throughput_Mtokens_per_sec）：每秒处理的Token数量，单位为百万tokens/秒（M tokens/sec）
  - 解码吞吐量（decode_throughput_Mtokens_per_sec）：每秒处理的Token数量，单位为百万tokens/秒
  - 计算公式：`throughput = 1e9 / avg_latency_ns / 1e6`

- **压缩指标**：
  - 压缩比（compression_ratio）：原始结构体大小与压缩后字节数的比值
  - 每Token字节数（bytes_per_token）：压缩后平均每个Token的字节数

### 测量方法

实验采用连续内存缓冲区存储编码后的Token数据，避免使用嵌套结构（如`vector<vector<uint8_t>>`）导致的间接访问开销。Encode操作测量从Token结构体到字节流的memcpy延迟，Decode操作在预热后测量从字节流到Token结构体的memcpy延迟。这些测量操作模拟了NIC硬件序列化单元的核心计算任务，即数据结构与字节流之间的转换。

**性能指标单位说明：**
- **延迟**：使用纳秒（ns）作为单位，更符合NIC硬件序列化单元的延迟特征。现代NIC硬件序列化单元的单次操作延迟通常在1-10纳秒级别，使用纳秒可以更精确地评估硬件性能需求。
- **带宽**：使用MB/s（兆字节/秒）作为单位，直接反映序列化操作的数据传输速率，便于与NIC的总带宽能力进行对比。
- **吞吐量**：使用M tokens/sec（百万tokens/秒）作为单位，更符合硬件规格描述的习惯，便于理解大规模场景下的性能表现。

**关键设计决策：**

1. **内存布局**：使用单个`std::vector<uint8_t>`作为连续缓冲区，最大化缓存局部性。这一设计对应NIC硬件中的片上缓冲区（on-chip buffer）设计，确保数据访问的连续性。

2. **预热机制**：Decode操作前进行预热（至少1000次操作），减少首次访问的缓存miss影响。这模拟了硬件序列化单元在稳定运行状态下的性能特征。

3. **精确计时**：使用高分辨率时钟，避免系统调用和上下文切换的开销，确保测量结果反映纯计算性能，而非系统调用开销。

4. **统计方法**：每个配置重复10次，计算平均值和95th分位数，提供足够的样本量进行统计分析，并识别性能波动。

5. **硬件对应性**：测量操作直接对应NIC硬件序列化单元的核心功能，实验结果可以指导硬件设计中的吞吐量目标、缓存大小和流水线深度等关键参数。

## 4.4 实验实施

### 编译与构建

实验程序使用CMake构建系统编译，具体命令如下：

```bash
mkdir build && cd build
cmake -DCMAKE_BUILD_TYPE=Release ..
make exp_a1_compress
```

编译选项设置为`-O2`优化级别，启用所有警告选项以检测潜在问题。

### 实验执行

实验程序通过命令行参数配置，支持以下选项：

- `--type`: Token类型（PD、MR、CQ、QP）
- `--N_values`: 数据规模列表，逗号分隔（如：1000,10000,100000,1000000）
- `--iters`: 重复执行次数（默认10次）
- `--random`或`--typical`: 字段分布模式
- `--output`: 输出JSON文件路径

典型执行命令示例：

```bash
./exp_a1_compress \
    --type=QP \
    --N_values=1000,10000,100000,1000000 \
    --iters=10 \
    --random \
    --output=results.json
```

### 结果记录

实验结果以JSON格式保存，包含完整的实验配置和性能指标。每个结果包含：Token类型、数据规模、重复次数、延迟统计（平均值和95th分位数，单位：纳秒）、带宽指标（单位：MB/s）、吞吐量（单位：M tokens/sec）、压缩比和字节数统计。

**性能指标示例：**
- 延迟：1.37 ns/op（编码）、1.43 ns/op（解码）
- 带宽：9.73 GB/s（编码）、9.33 GB/s（解码）  
- 吞吐量：729 M tokens/sec（编码）、699 M tokens/sec（解码）

这些指标为NIC硬件序列化单元的设计提供了明确的性能目标，便于在硬件设计阶段设定规格和验证目标。

## 4.5 实验局限性与硬件对应关系

### 软件模拟的局限性

需要说明的是，本实验采用软件模拟方式评估NIC硬件序列化能力，存在以下局限性：

1. **硬件实现细节**：真实NIC硬件序列化单元可能采用专用电路（ASIC）或FPGA实现，其性能特征可能与通用CPU上的memcpy操作存在差异。专用硬件可能实现更高的并行度或流水线深度。

2. **片上资源限制**：NIC硬件序列化单元受到片上资源（缓存、寄存器、流水线级数）的限制，而软件模拟在通用CPU上执行，资源约束不同。实验结果更多反映性能的理论上限。

3. **网络传输集成**：真实NIC硬件序列化单元通常与网络传输引擎集成，可能采用流水线方式同时处理序列化和传输，而本实验仅测量序列化操作的独立性能。

4. **并发处理能力**：真实NIC硬件可能支持多个序列化单元的并行工作，而本实验采用单线程顺序执行，未考虑硬件并行能力。

### 软件模拟与硬件性能的对应关系

尽管存在局限性，软件模拟结果仍具有重要的参考价值：

1. **性能上限评估**：软件模拟结果可以视为硬件序列化单元性能的理论上限，因为通用CPU的memcpy操作已经经过高度优化，专用硬件在相同计算复杂度下不太可能显著超越。

2. **设计目标设定**：实验结果可以为硬件设计提供明确的性能目标，例如：序列化吞吐量应达到多少tokens/sec，延迟应控制在多少微秒以内。

3. **瓶颈识别**：通过分析软件模拟中的性能瓶颈（如缓存效率、内存访问模式），可以指导硬件设计中的资源分配和优化方向。

4. **验证基准**：当真实硬件实现后，软件模拟结果可以作为验证基准，评估硬件实现的效率是否达到预期。

### 实验结果的应用价值

本实验的软件模拟结果主要用于：
- **硬件设计阶段**：为NIC序列化单元的规格设计提供性能参考
- **性能预测**：在硬件实现前预测序列化性能，指导系统架构设计
- **优化方向**：识别性能瓶颈，指导硬件优化重点
- **验证基准**：作为硬件实现的验证目标

需要注意的是，最终的系统性能评估应在真实NIC硬件平台上进行验证，软件模拟结果主要作为设计和优化的参考依据。

## 4.6 实验可重复性

为确保实验的可重复性，我们记录了完整的实验环境信息：

- **硬件配置**：CPU型号、核心数、频率、缓存大小、内存规格
- **软件版本**：编译器版本、操作系统版本、CMake版本
- **编译选项**：优化级别、编译标志
- **运行时环境**：CPU频率调节器设置、进程绑定等
- **实验代码**：开源代码库，包含完整的实验实现

所有实验结果以JSON格式保存，便于后续分析和验证。实验代码和结果数据可在[项目仓库]获取。

---

**注：** 以上内容可直接用于论文的实验章节。请根据实际硬件配置填写具体的数值（如内存容量、频率等），并根据需要使用方括号标记需要补充的信息。

